# To see the complete list of configurable parameters see:
# https://github.com/ray-project/ray/blob/master/rllib/agents/trainer.py


# === Settings for Rollout Worker processes ===
num_workers: 1
rollout_fragment_length: 16
num_envs_per_worker: 1
batch_mode: "complete_episodes"


# === Settings for the Trainer process ===
num_gpus: 0.6
train_batch_size: 64
optimizer: "Adam"
model: {

  # == Atari ==
  dim: 300,

  # === Built-in options ===
  conv_filters: [
    [16, [5, 5], 4],
    [32, [5, 5], 2],
    [32, [5, 5], 2],
    [64, [5, 5], 1],
    [64, [5, 5], 2],
    [128, [5, 5], 2],
    [512, [5, 5], 1],
  ]

  # == LSTM ==
  # "use_lstm": False,
  # "max_seq_len": 20,
  # "lstm_cell_size": 256,
  # "lstm_use_prev_action": False,
  # "lstm_use_prev_reward": False,
}


# === PPO ===
# use_critic: True
# use_gae: True
# lambda: 1.0
# kl_coeff: 0.2
sgd_minibatch_size: 32
# shuffle_sequences: True
# num_sgd_iter: 30
# lr_schedule: None
# entropy_coeff: 0.0
# entropy_coeff_schedule: None
# clip_param: 0.3
# vf_clip_param: 10.0
# grad_clip: None
# kl_target: 0.01


# === Debug Settings ===
# monitor: False
# log_level: "WARN"
# log_sys_usage: True


# === Deep Learning Framework Settings ===
framework: "torch"


# === Exploration Settings ===
exploration_config: {
    "type": "StochasticSampling"
  }
# exploration_config: {
#   type: "SoftQ",
#   temperature: 1.0,
# }


# === Evaluation Settings ===
# evaluation_interval: None
# evaluation_num_episodes: 10
# in_evaluation: False
# evaluation_config: {}
# evaluation_num_workers: 0
# custom_eval_function: None


# === Advanced Rollout Settings ===
# remote_worker_envs: False
# seed: None
# extra_python_environs_for_driver: {}
# extra_python_environs_for_worker: {}
# timesteps_per_iteration: 20000


# === Advanced Resource Settings ===
num_cpus_per_worker: 4
num_gpus_per_worker: 0.4
num_cpus_for_driver: 4
# memory: 1000000000
# object_store_memory: 1000000000
# memory_per_worker: 1000000000
# object_store_memory_per_worker: 1000000000


# === Environment Settings ===
# gamma: 0.99
# horizon: None
# soft_horizon: False
# no_done_at_end: False
# normalize_actions: False
# clip_rewards: None
# clip_actions: True
# lr: 0.0025
env_config:
  carla:
    host: "localhost"
    timeout: 30.0
    timestep: 0.05
    retries_on_error: 25
    resolution_x: 600
    resolution_y: 600
    quality_level: "Low"
    enable_map_assets: True
    enable_rendering: True
    show_display: True

  experiment:
    hero:
      blueprint: "vehicle.audi.a2"
      sensors:
        cam_sem_seg_front:
          type: "sensor.camera.semantic_segmentation"
          transform: "0,0,2,0,0,0"
          image_size_x: 300
          image_size_y: 300
        cam_sem_seg_left:
          type: "sensor.camera.semantic_segmentation"
          transform: "0,0,2,0,-90.0,0"
          image_size_x: 300
          image_size_y: 300
        cam_sem_seg_right:
          type: "sensor.camera.semantic_segmentation"
          transform: "0,0,2,0,90.0,0"
          image_size_x: 300
          image_size_y: 300
        collision:
          type: "sensor.other.collision"
        # lidar:
        #   type: "sensor.lidar.ray_cast "
        #   transform: "0,0,2,0,0,0"
    background_activity:
      n_vehicles: 10
      n_walkers: 0
      tm_hybrid_mode: True
    town: [
      # "Town07_Opt",
      # "Town01_Opt",
      # "Town03_Opt",
      # "Town02_Opt",
      "Town05_Opt"
      ]
    weather: "dynamic"
    others:
      framestack: 4
      max_time_idle: 600
      max_time_episode: 6400