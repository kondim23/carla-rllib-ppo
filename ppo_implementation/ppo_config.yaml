# This project was sourced by https://github.com/carla-simulator/rllib-integration/tree/main 
# and was modified within the development of the bachelor thesis "End-To-End On-Policy 
# Reinforcement Learning on a Self-Driving Car in Urban Settings" by Konstantinos Dimitrakopoulos,
# student of the department of Informatics and Telecommunications, University of Athens


# === Settings for Rollout Worker processes ===
num_workers: 2
rollout_fragment_length: 16
num_envs_per_worker: 1
batch_mode: "complete_episodes"


# === Settings for the Trainer process ===
num_gpus: 1
train_batch_size: 64
optimizer: "Adam"
model: {
  dim: 300,
  conv_filters: [
    [16, [5, 5], 4],
    [32, [5, 5], 2],
    [32, [5, 5], 2],
    [64, [5, 5], 1],
    [64, [5, 5], 2],
    [128, [5, 5], 2],
    [512, [5, 5], 1],
  ]
}


# === PPO ===
use_critic: True
use_gae: True
lambda: 1.0
kl_coeff: 0.2
sgd_minibatch_size: 32
shuffle_sequences: True
num_sgd_iter: 30
lr_schedule: None
entropy_coeff: 0.0
entropy_coeff_schedule: None
clip_param: 0.3
vf_clip_param: 10.0
grad_clip: None
kl_target: 0.01


# === Debug Settings ===
# monitor: False
# log_level: "WARN"
# log_sys_usage: True


# === Deep Learning Framework Settings ===
framework: "torch"


# === Exploration Settings ===
exploration_config: {
    "type": "StochasticSampling"
  }


# === Evaluation Settings ===
evaluation_interval: None
evaluation_num_episodes: 10
in_evaluation: False
evaluation_config: {}
evaluation_num_workers: 0
custom_eval_function: None


# === Advanced Rollout Settings ===
remote_worker_envs: False
seed: None
extra_python_environs_for_driver: {}
extra_python_environs_for_worker: {}
# timesteps_per_iteration: 20000


# === Advanced Resource Settings ===
num_cpus_per_worker: 3
num_gpus_per_worker: 0.8
# num_cpus_for_driver: 4
# memory: 1000000000
# object_store_memory: 1000000000
# memory_per_worker: 1000000000
# object_store_memory_per_worker: 1000000000


# === Environment Settings ===
gamma: 0.99
horizon: None
soft_horizon: False
no_done_at_end: False
normalize_actions: False
clip_rewards: None
clip_actions: True
lr: 0.0025
env_config:
  carla:
    host: "localhost"
    timeout: 30.0
    timestep: 0.05
    retries_on_error: 25
    resolution_x: 600
    resolution_y: 600
    quality_level: "Low"
    enable_map_assets: True
    enable_rendering: True
    show_display: True

  experiment:
    hero:
      blueprint: "vehicle.audi.a2"
      sensors:
        cam_sem_seg_front:
          type: "sensor.camera.semantic_segmentation"
          transform: "0,0,2,0,0,0"
          image_size_x: 300
          image_size_y: 300
        cam_sem_seg_left:
          type: "sensor.camera.semantic_segmentation"
          transform: "0,0,2,0,-90.0,0"
          image_size_x: 300
          image_size_y: 300
        cam_sem_seg_right:
          type: "sensor.camera.semantic_segmentation"
          transform: "0,0,2,0,90.0,0"
          image_size_x: 300
          image_size_y: 300
        collision:
          type: "sensor.other.collision"
    background_activity:
      n_vehicles: 100
      n_walkers: 0
      tm_hybrid_mode: True
    town: [
      "Town07_Opt",
      "Town01_Opt",
      "Town03_Opt",
      "Town02_Opt",
      "Town05_Opt"
      ]
    weather: "dynamic"
    others:
      framestack: 4
      max_time_idle: 600
      max_time_episode: 6400